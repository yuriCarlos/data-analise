{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import tweetProccess\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk, re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "\n",
    "'''docs = ['this this this book',\n",
    "        'this cat good',\n",
    "        'cat good shit',\n",
    "       'cat bad',\n",
    "       'cat killer',\n",
    "       'cat injustice']'''\n",
    "\n",
    "treat = tweetProccess.FileTreat()\n",
    "\n",
    "doc_num = 300\n",
    "\n",
    "docs = treat.getBadTweets()[:doc_num]\n",
    "\n",
    "#print(stopwords.words('english')[0:3])\n",
    "\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = [i for i in text if i not in stopwords.words('english')]\n",
    "    \n",
    "    return text\n",
    "    \n",
    "\n",
    "def get_coocurrence_matrix():\n",
    "    cv = CountVectorizer(tokenizer=tokenize, ngram_range=(1,1))\n",
    "    com = cv.fit_transform(docs)\n",
    "    \n",
    "    #print(com.toarray())\n",
    "    \n",
    "    co_matrix = (com.T * com)\n",
    "    return co_matrix.toarray()\n",
    "\n",
    "def get_tf():\n",
    "    '''gets the term frequency matrix\n",
    "    returns the vocabulary and the tf matrix'''\n",
    "    cv = CountVectorizer(tokenizer=tokenize)\n",
    "    tf = cv.fit_transform(docs)\n",
    "    tf = tf.T.toarray()\n",
    "    \n",
    "    tf = [sum(i) for i in tf]\n",
    "    \n",
    "    \n",
    "    return cv.get_feature_names(), tf\n",
    "\n",
    "def getdictwords(path):\n",
    "    f = open(path, 'r', encoding=\"ISO-8859-1\")\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    return [i.replace('\\n', '') for i in lines]\n",
    "\n",
    "positive_words = getdictwords('dataset/src/positive-words.txt')\n",
    "negative_words = getdictwords('dataset/src/negative-words.txt')\n",
    "\n",
    "def get_reference(names):\n",
    "    '''gets a dictionary word->index'''\n",
    "    d = {}\n",
    "    for i in range(len(names)):\n",
    "        d[names[i]] = i\n",
    "        \n",
    "    return d\n",
    "    \n",
    "def get_pmi(coocurrence_matrix, tf):\n",
    "    pmi = []\n",
    "    for idx in range(len(tf)):\n",
    "        pmi.append([])\n",
    "        for jdx in range(len(tf)):\n",
    "            #gets the coocurrence probability\n",
    "            num = coocurrence_matrix[idx][jdx] / doc_num\n",
    "            #gets the product of the first term and second term probability\n",
    "            den = (tf[idx] / doc_num) * (tf[jdx] / doc_num)\n",
    "            #gets the measure of the dependence of these two words\n",
    "            dep =  num/den\n",
    "            pmi[idx].append(0 if dep == 0 else math.log(dep, 2))\n",
    "    \n",
    "    return pmi\n",
    "\n",
    "def filter_structure(text):\n",
    "    '''gets the patern of words described in the article www.aclweb.org/anthology/P02-1053.pdf'''\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    words = []\n",
    "    \n",
    "    for i in range(len(tags) - 1):\n",
    "        if tags[i][1] == 'JJ' and (tags[i + 1][1] == 'NN' or tags[i + 1][1] == 'NNS'):\n",
    "            words.extend([tags[i][0], tags[i + 1][0]])\n",
    "        elif tags[i][1] == 'JJ' and tags[i + 1][1] == 'JJ':\n",
    "            words.extend([tags[i][0], tags[i + 1][0]])\n",
    "        elif (tags[i][1] == 'RB' or tags[i][1] == 'RBR' or tags[i][1] == 'RBS') and (tags[i + 1][1] == 'JJ'):\n",
    "            words.extend([tags[i][0], tags[i + 1][0]])\n",
    "        elif (tags[i][1] == 'NN' or tags[i][1] == 'NNS') and tags[i + 1][1] == 'JJ':\n",
    "            words.extend([tags[i][0], tags[i + 1][0]])\n",
    "        elif (tags[i][1] == 'RB' or tags[i][1] == 'RBR' or tags[i][1] == 'RBS') and (tags[i + 1][1] == 'VB' or tags[i + 1][1] == 'VBD' or tags[i + 1][1] == 'VBN' or tags[i + 1][1] == 'VBG'):\n",
    "            words.extend([tags[i][0], tags[i + 1][0]])\n",
    "    \n",
    "    return words\n",
    "\n",
    "def filter_vocab(vocab, words):\n",
    "    '''gets the intersection between vocab and words with the id in vocab'''\n",
    "    intersect = []\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            intersect.append(word)\n",
    "    return intersect\n",
    "            \n",
    "def get_semantic_orientation(pmi, phrase, positive_id, negative_id, ref):\n",
    "    #gets the words that matter\n",
    "    words = filter_structure(phrase)\n",
    "    negative = .0\n",
    "    positive = .0\n",
    "    #for each word sum the positive and negative association with positive and negative words\n",
    "    for word in words:\n",
    "        if word in ref:\n",
    "            positive += sum(pmi[ref[word.lower()]][ref[i]]  for i in positive_id)\n",
    "            negative += sum(pmi[ref[word.lower()]][ref[i]]  for i in negative_id)\n",
    "        \n",
    "    if len(words) > 0:\n",
    "        positive /= len(words)/2\n",
    "        negative /= len(words)/2\n",
    "    return positive - negative\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cc149c93cf3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mco_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coocurrence_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#gets the PMI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-2fd65b9986f9>\u001b[0m in \u001b[0;36mget_pmi\u001b[0;34m(coocurrence_matrix, tf)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m#gets the coocurrence probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoocurrence_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdoc_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m#gets the product of the first term and second term probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdoc_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdoc_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_num' is not defined"
     ]
    }
   ],
   "source": [
    "#gets the tf and vocab\n",
    "vocab, tf = get_tf()\n",
    "#print(vocab)\n",
    "#gets coocurrence matrix\n",
    "co_matrix = get_coocurrence_matrix()\n",
    "#gets the PMI\n",
    "pmi = get_pmi(co_matrix, tf)\n",
    "print(len(co_matrix))\n",
    "print(len(co_matrix[0]))\n",
    "print(len(tf))\n",
    "#gets the column reference\n",
    "ref = get_reference(vocab)\n",
    "#gets positive and negative words that are in our vocabulary\n",
    "positive_id, negative_id = filter_vocab(vocab, positive_words), filter_vocab(vocab, negative_words)\n",
    "\n",
    "#print(positive_id)\n",
    "#print(negative_id)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#idx = 187\n",
    "print(docs[173])\n",
    "for i in range(len(docs)):\n",
    "    print(str(i))\n",
    "    print(get_semantic_orientation(pmi, docs[i],positive_id, negative_id, ref))\n",
    "    print('==========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
